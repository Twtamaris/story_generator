{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = [\n",
    "\"\"\"\"The Forgotten Map\": In a dusty old library, a young researcher discovers a mysterious map hidden within the pages of an ancient book. The map seems to lead to a long-lost kingdom filled with treasures and secrets. As the researcher delves deeper into deciphering the map's clues, they uncover unexpected challenges and adversaries determined to reach the treasure first.\"\"\",\n",
    "\n",
    "\"\"\"\"Whispers in the Woods\": In a secluded forest, strange whispers are heard by anyone who dares to enter. A curious teenager, known for their bravery, decides to investigate. As they venture deeper into the woods, they encounter enigmatic creatures and learn that the whispers hold the key to a forgotten prophecy that could change the fate of their world.\"\"\",\n",
    "\n",
    "\"\"\"\"The Last Beacon\": In a world plunged into darkness after an ancient catastrophe, a young engineer discovers an ancient lighthouse said to hold the power to restore light to the world. With the help of a group of unlikely allies, the engineer embarks on a perilous journey across treacherous lands, facing formidable challenges and adversaries who seek to keep the world in eternal darkness.\"\"\",\n",
    "\n",
    "\"\"\"\"Echoes of Time\": A gifted physicist invents a time-traveling device capable of sending messages to the past. However, the messages sent cause unforeseen ripples through time, altering events in unexpected ways. As the fabric of reality begins to unravel, the physicist races against time to correct the changes before irreparable damage occurs.\"\"\",\n",
    "\n",
    "\"\"\"\"The Dream Catcher\": In a town plagued by a series of haunting nightmares, a young artist discovers they have the ability to enter dreams and alter their course. Tasked with unraveling the mystery behind these nightmares, they navigate a surreal dream world, facing manifestations of people's deepest fears and secrets, all while trying to prevent a looming catastrophe that threatens to merge the dream realm with reality.\"\"\",\n",
    "    \n",
    "    # Add more stories here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this checks the longest story with most number of words\n",
    "max_len = max(len(story.split()) for story in stories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000  # Choose an appropriate vocabulary size\n",
    "embedding_dim = 100  # Embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  22,\n",
       "  11,\n",
       "  5,\n",
       "  2,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  2,\n",
       "  12,\n",
       "  23,\n",
       "  13,\n",
       "  2,\n",
       "  45,\n",
       "  11,\n",
       "  46,\n",
       "  47,\n",
       "  1,\n",
       "  48,\n",
       "  4,\n",
       "  14,\n",
       "  15,\n",
       "  49,\n",
       "  1,\n",
       "  11,\n",
       "  50,\n",
       "  3,\n",
       "  51,\n",
       "  3,\n",
       "  2,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  9,\n",
       "  56,\n",
       "  6,\n",
       "  24,\n",
       "  16,\n",
       "  1,\n",
       "  23,\n",
       "  57,\n",
       "  25,\n",
       "  17,\n",
       "  58,\n",
       "  1,\n",
       "  59,\n",
       "  60,\n",
       "  7,\n",
       "  61,\n",
       "  26,\n",
       "  27,\n",
       "  6,\n",
       "  28,\n",
       "  62,\n",
       "  3,\n",
       "  63,\n",
       "  1,\n",
       "  64,\n",
       "  65],\n",
       " [18,\n",
       "  5,\n",
       "  1,\n",
       "  29,\n",
       "  5,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  18,\n",
       "  69,\n",
       "  70,\n",
       "  30,\n",
       "  71,\n",
       "  31,\n",
       "  72,\n",
       "  3,\n",
       "  32,\n",
       "  2,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  19,\n",
       "  77,\n",
       "  78,\n",
       "  3,\n",
       "  79,\n",
       "  16,\n",
       "  7,\n",
       "  80,\n",
       "  25,\n",
       "  17,\n",
       "  1,\n",
       "  29,\n",
       "  7,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  6,\n",
       "  84,\n",
       "  20,\n",
       "  1,\n",
       "  18,\n",
       "  33,\n",
       "  1,\n",
       "  85,\n",
       "  3,\n",
       "  2,\n",
       "  22,\n",
       "  86,\n",
       "  20,\n",
       "  87,\n",
       "  88,\n",
       "  1,\n",
       "  89,\n",
       "  4,\n",
       "  19,\n",
       "  8],\n",
       " [1,\n",
       "  90,\n",
       "  91,\n",
       "  5,\n",
       "  2,\n",
       "  8,\n",
       "  92,\n",
       "  17,\n",
       "  34,\n",
       "  93,\n",
       "  14,\n",
       "  15,\n",
       "  35,\n",
       "  2,\n",
       "  12,\n",
       "  36,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  94,\n",
       "  95,\n",
       "  3,\n",
       "  33,\n",
       "  1,\n",
       "  96,\n",
       "  3,\n",
       "  97,\n",
       "  98,\n",
       "  3,\n",
       "  1,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  99,\n",
       "  4,\n",
       "  2,\n",
       "  100,\n",
       "  4,\n",
       "  101,\n",
       "  102,\n",
       "  1,\n",
       "  36,\n",
       "  103,\n",
       "  104,\n",
       "  2,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  37,\n",
       "  110,\n",
       "  27,\n",
       "  6,\n",
       "  28,\n",
       "  31,\n",
       "  111,\n",
       "  3,\n",
       "  112,\n",
       "  1,\n",
       "  8,\n",
       "  5,\n",
       "  113,\n",
       "  34],\n",
       " [114,\n",
       "  4,\n",
       "  10,\n",
       "  2,\n",
       "  115,\n",
       "  38,\n",
       "  116,\n",
       "  2,\n",
       "  10,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  4,\n",
       "  120,\n",
       "  39,\n",
       "  3,\n",
       "  1,\n",
       "  121,\n",
       "  122,\n",
       "  1,\n",
       "  39,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  10,\n",
       "  128,\n",
       "  129,\n",
       "  5,\n",
       "  26,\n",
       "  130,\n",
       "  16,\n",
       "  1,\n",
       "  131,\n",
       "  4,\n",
       "  40,\n",
       "  132,\n",
       "  3,\n",
       "  133,\n",
       "  1,\n",
       "  38,\n",
       "  134,\n",
       "  135,\n",
       "  10,\n",
       "  3,\n",
       "  136,\n",
       "  1,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141],\n",
       " [1,\n",
       "  21,\n",
       "  142,\n",
       "  5,\n",
       "  2,\n",
       "  143,\n",
       "  144,\n",
       "  30,\n",
       "  2,\n",
       "  145,\n",
       "  4,\n",
       "  146,\n",
       "  41,\n",
       "  2,\n",
       "  12,\n",
       "  147,\n",
       "  13,\n",
       "  7,\n",
       "  148,\n",
       "  1,\n",
       "  149,\n",
       "  3,\n",
       "  32,\n",
       "  150,\n",
       "  6,\n",
       "  151,\n",
       "  19,\n",
       "  152,\n",
       "  153,\n",
       "  9,\n",
       "  154,\n",
       "  1,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  41,\n",
       "  7,\n",
       "  158,\n",
       "  2,\n",
       "  159,\n",
       "  21,\n",
       "  8,\n",
       "  37,\n",
       "  160,\n",
       "  4,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  6,\n",
       "  24,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  3,\n",
       "  167,\n",
       "  2,\n",
       "  168,\n",
       "  35,\n",
       "  20,\n",
       "  169,\n",
       "  3,\n",
       "  170,\n",
       "  1,\n",
       "  21,\n",
       "  171,\n",
       "  9,\n",
       "  40]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(stories)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\n",
    "#     [1, 2, 3, 4, 1, 5],\n",
    "#     [1, 6, 7, 8, 9],\n",
    "#     [10, 11, 12, 4, 1, 13]\n",
    "# ]\n",
    "## converts this code to this using\n",
    "# padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "# [\n",
    "#     [1, 2, 3, 4, 1, 5],    # Unchanged - already at max_len\n",
    "#     [1, 6, 7, 8, 9, 0],   # Padded with zeros at the end\n",
    "#     [10, 11, 12, 4, 1, 13]  # Unchanged - already at max_len\n",
    "# ]\n",
    "# # \n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 67) for input KerasTensor(type_spec=TensorSpec(shape=(None, 67), dtype=tf.float32, name='embedding_16_input'), name='embedding_16_input', description=\"created by layer 'embedding_16_input'\"), but it was called on an input with incompatible shape (None, 1000).\n"
     ]
    }
   ],
   "source": [
    "# Building the generator model\n",
    "generator = Sequential()\n",
    "generator.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "generator.add(Bidirectional(LSTM(128)))\n",
    "# activation='softmax' is used because the generator's output should represent \n",
    "# probabilities for each element in vocab_size in the vocabulary.\n",
    "generator.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# Building the discriminator model\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "discriminator.add(Bidirectional(LSTM(128)))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# Combining generator and discriminator as part of GAN\n",
    "discriminator.trainable = False\n",
    "gan_input = generator.input\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_train_function.<locals>.train_function at 0x0000018D32D63670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_9' (type Functional).\n    \n    Input 0 of layer \"sequential_21\" is incompatible with the layer: expected shape=(None, 67), found shape=(32, 1000)\n    \n    Call arguments received by layer 'model_9' (type Functional):\n      • inputs=tf.Tensor(shape=(32, 67), dtype=int32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m y_mislabeled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Training the GAN (generator) to mislead the discriminator\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mislabeled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Printing and tracking loss for observation\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:2478\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2474\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2476\u001b[0m     )\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2478\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2480\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenp915z2o.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1233\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1230\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[0;32m   1232\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1233\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1235\u001b[0m     outputs,\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1237\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1238\u001b[0m )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1222\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1222\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1023\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m-> 1023\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1024\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_9' (type Functional).\n    \n    Input 0 of layer \"sequential_21\" is incompatible with the layer: expected shape=(None, 67), found shape=(32, 1000)\n    \n    Call arguments received by layer 'model_9' (type Functional):\n      • inputs=tf.Tensor(shape=(32, 67), dtype=int32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Training the GAN\n",
    "epochs = 100 # Choose an appropriate number of epochs\n",
    "batch_size = 32  # Define batch size\n",
    "for epoch in range(epochs):\n",
    "    # Generating noise data for the generator\n",
    "    noise = np.random.randint(0, vocab_size, size=(batch_size, max_len))\n",
    "    \n",
    "    # Generating stories using the generator model\n",
    "    generated_stories = generator.predict(noise)\n",
    "    \n",
    "    # Padding the generated stories to match the sequence length of real stories\n",
    "    generated_stories_padded = pad_sequences(generated_stories, maxlen=max_len, padding='post')\n",
    "    \n",
    "    # Selecting real stories randomly from the dataset\n",
    "    real_stories = padded_sequences[np.random.randint(0, len(padded_sequences), size=batch_size)]\n",
    "    generated_stories\n",
    "    # Concatenating real and generated stories\n",
    "    x_combined = np.concatenate([real_stories, generated_stories_padded])\n",
    "    \n",
    "    # Creating labels for the combined real and generated stories\n",
    "    y_combined = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    \n",
    "    # Training the discriminator on the combined real and generated stories\n",
    "    d_loss = discriminator.train_on_batch(x_combined, y_combined)\n",
    "    \n",
    "    # Generating new noise data for the generator\n",
    "    noise = np.random.randint(0, vocab_size, size=(batch_size, max_len))\n",
    "    \n",
    "    # Creating labels for the generated data to mislead the discriminator\n",
    "    y_mislabeled = np.ones((batch_size, 1))\n",
    "    \n",
    "    # Training the GAN (generator) to mislead the discriminator\n",
    "    g_loss = gan.train_on_batch(noise, y_mislabeled)\n",
    "    \n",
    "    # Printing and tracking loss for observation\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Generator Loss: {g_loss}, Discriminator Loss: {d_loss}\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 67), (32, 67, 100))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stories.shape, generated_stories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_1' (type Functional).\n    \n    Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 67), found shape=(32, 10000)\n    \n    Call arguments received by layer 'model_1' (type Functional):\n      • inputs=tf.Tensor(shape=(32, 67), dtype=int32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mislabeled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m g_loss\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:2478\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2474\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2476\u001b[0m     )\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2478\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2480\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenp915z2o.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1233\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1230\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[0;32m   1232\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1233\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1235\u001b[0m     outputs,\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1237\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1238\u001b[0m )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1222\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1222\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1023\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m-> 1023\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1024\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_1' (type Functional).\n    \n    Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 67), found shape=(32, 10000)\n    \n    Call arguments received by layer 'model_1' (type Functional):\n      • inputs=tf.Tensor(shape=(32, 67), dtype=int32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "g_loss = gan.train_on_batch(noise, y_mislabeled)\n",
    "\n",
    "g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[114,   4,  10, ...,   0,   0,   0],\n",
       "        [  1,  22,  11, ...,   0,   0,   0],\n",
       "        [114,   4,  10, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]]),\n",
       " (64, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_combined, y_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18,   5,   1, ...,   0,   0,   0],\n",
       "       [114,   4,  10, ...,   0,   0,   0],\n",
       "       [114,   4,  10, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [114,   4,  10, ...,   0,   0,   0],\n",
       "       [  1,  21, 142, ..., 171,   9,  40],\n",
       "       [114,   4,  10, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hehe = np.random.randint(0, len(padded_sequences), size=batch_size)\n",
    "hehe\n",
    "padded_sequences[hehe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[9.98720134e-05, 1.00048579e-04, 9.99957701e-05, ...,\n",
       "         9.99809563e-05, 9.98402975e-05, 1.00122576e-04],\n",
       "        [1.00180543e-04, 1.00268917e-04, 9.99549738e-05, ...,\n",
       "         1.00082485e-04, 1.00082834e-04, 1.00275967e-04],\n",
       "        [1.00052443e-04, 1.00122641e-04, 1.00267549e-04, ...,\n",
       "         1.00181518e-04, 1.00085963e-04, 1.00214784e-04],\n",
       "        ...,\n",
       "        [1.00170517e-04, 1.00021512e-04, 1.00016783e-04, ...,\n",
       "         9.97081588e-05, 1.00030004e-04, 1.00188619e-04],\n",
       "        [9.99131589e-05, 9.99968252e-05, 1.00044766e-04, ...,\n",
       "         1.00066762e-04, 1.00083678e-04, 9.99090626e-05],\n",
       "        [1.00117308e-04, 1.00013240e-04, 9.99811964e-05, ...,\n",
       "         9.99144031e-05, 9.98461110e-05, 1.00163124e-04]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_combined = np.concatenate([real_stories, generated_stories])\n",
    "generated_stories.shape, generated_stories_padded.shape\n",
    "generated_stories_padded, generated_stories\n",
    "    # y_combined = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
