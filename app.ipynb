{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = [\n",
    "\"\"\"\"The Forgotten Map\": In a dusty old library, a young researcher discovers a mysterious map hidden within the pages of an ancient book. The map seems to lead to a long-lost kingdom filled with treasures and secrets. As the researcher delves deeper into deciphering the map's clues, they uncover unexpected challenges and adversaries determined to reach the treasure first.\"\"\",\n",
    "\n",
    "\"\"\"\"Whispers in the Woods\": In a secluded forest, strange whispers are heard by anyone who dares to enter. A curious teenager, known for their bravery, decides to investigate. As they venture deeper into the woods, they encounter enigmatic creatures and learn that the whispers hold the key to a forgotten prophecy that could change the fate of their world.\"\"\",\n",
    "\n",
    "\"\"\"\"The Last Beacon\": In a world plunged into darkness after an ancient catastrophe, a young engineer discovers an ancient lighthouse said to hold the power to restore light to the world. With the help of a group of unlikely allies, the engineer embarks on a perilous journey across treacherous lands, facing formidable challenges and adversaries who seek to keep the world in eternal darkness.\"\"\",\n",
    "\n",
    "\"\"\"\"Echoes of Time\": A gifted physicist invents a time-traveling device capable of sending messages to the past. However, the messages sent cause unforeseen ripples through time, altering events in unexpected ways. As the fabric of reality begins to unravel, the physicist races against time to correct the changes before irreparable damage occurs.\"\"\",\n",
    "\n",
    "\"\"\"\"The Dream Catcher\": In a town plagued by a series of haunting nightmares, a young artist discovers they have the ability to enter dreams and alter their course. Tasked with unraveling the mystery behind these nightmares, they navigate a surreal dream world, facing manifestations of people's deepest fears and secrets, all while trying to prevent a looming catastrophe that threatens to merge the dream realm with reality.\"\"\",\n",
    "    \n",
    "    # Add more stories here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this checks the longest story with most number of words\n",
    "max_len = max(len(story.split()) for story in stories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000  # Choose an appropriate vocabulary size\n",
    "embedding_dim = 100  # Embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  22,\n",
       "  11,\n",
       "  5,\n",
       "  2,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  2,\n",
       "  12,\n",
       "  23,\n",
       "  13,\n",
       "  2,\n",
       "  45,\n",
       "  11,\n",
       "  46,\n",
       "  47,\n",
       "  1,\n",
       "  48,\n",
       "  4,\n",
       "  14,\n",
       "  15,\n",
       "  49,\n",
       "  1,\n",
       "  11,\n",
       "  50,\n",
       "  3,\n",
       "  51,\n",
       "  3,\n",
       "  2,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  9,\n",
       "  56,\n",
       "  6,\n",
       "  24,\n",
       "  16,\n",
       "  1,\n",
       "  23,\n",
       "  57,\n",
       "  25,\n",
       "  17,\n",
       "  58,\n",
       "  1,\n",
       "  59,\n",
       "  60,\n",
       "  7,\n",
       "  61,\n",
       "  26,\n",
       "  27,\n",
       "  6,\n",
       "  28,\n",
       "  62,\n",
       "  3,\n",
       "  63,\n",
       "  1,\n",
       "  64,\n",
       "  65],\n",
       " [18,\n",
       "  5,\n",
       "  1,\n",
       "  29,\n",
       "  5,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  18,\n",
       "  69,\n",
       "  70,\n",
       "  30,\n",
       "  71,\n",
       "  31,\n",
       "  72,\n",
       "  3,\n",
       "  32,\n",
       "  2,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  19,\n",
       "  77,\n",
       "  78,\n",
       "  3,\n",
       "  79,\n",
       "  16,\n",
       "  7,\n",
       "  80,\n",
       "  25,\n",
       "  17,\n",
       "  1,\n",
       "  29,\n",
       "  7,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  6,\n",
       "  84,\n",
       "  20,\n",
       "  1,\n",
       "  18,\n",
       "  33,\n",
       "  1,\n",
       "  85,\n",
       "  3,\n",
       "  2,\n",
       "  22,\n",
       "  86,\n",
       "  20,\n",
       "  87,\n",
       "  88,\n",
       "  1,\n",
       "  89,\n",
       "  4,\n",
       "  19,\n",
       "  8],\n",
       " [1,\n",
       "  90,\n",
       "  91,\n",
       "  5,\n",
       "  2,\n",
       "  8,\n",
       "  92,\n",
       "  17,\n",
       "  34,\n",
       "  93,\n",
       "  14,\n",
       "  15,\n",
       "  35,\n",
       "  2,\n",
       "  12,\n",
       "  36,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  94,\n",
       "  95,\n",
       "  3,\n",
       "  33,\n",
       "  1,\n",
       "  96,\n",
       "  3,\n",
       "  97,\n",
       "  98,\n",
       "  3,\n",
       "  1,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  99,\n",
       "  4,\n",
       "  2,\n",
       "  100,\n",
       "  4,\n",
       "  101,\n",
       "  102,\n",
       "  1,\n",
       "  36,\n",
       "  103,\n",
       "  104,\n",
       "  2,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  37,\n",
       "  110,\n",
       "  27,\n",
       "  6,\n",
       "  28,\n",
       "  31,\n",
       "  111,\n",
       "  3,\n",
       "  112,\n",
       "  1,\n",
       "  8,\n",
       "  5,\n",
       "  113,\n",
       "  34],\n",
       " [114,\n",
       "  4,\n",
       "  10,\n",
       "  2,\n",
       "  115,\n",
       "  38,\n",
       "  116,\n",
       "  2,\n",
       "  10,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  4,\n",
       "  120,\n",
       "  39,\n",
       "  3,\n",
       "  1,\n",
       "  121,\n",
       "  122,\n",
       "  1,\n",
       "  39,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  10,\n",
       "  128,\n",
       "  129,\n",
       "  5,\n",
       "  26,\n",
       "  130,\n",
       "  16,\n",
       "  1,\n",
       "  131,\n",
       "  4,\n",
       "  40,\n",
       "  132,\n",
       "  3,\n",
       "  133,\n",
       "  1,\n",
       "  38,\n",
       "  134,\n",
       "  135,\n",
       "  10,\n",
       "  3,\n",
       "  136,\n",
       "  1,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141],\n",
       " [1,\n",
       "  21,\n",
       "  142,\n",
       "  5,\n",
       "  2,\n",
       "  143,\n",
       "  144,\n",
       "  30,\n",
       "  2,\n",
       "  145,\n",
       "  4,\n",
       "  146,\n",
       "  41,\n",
       "  2,\n",
       "  12,\n",
       "  147,\n",
       "  13,\n",
       "  7,\n",
       "  148,\n",
       "  1,\n",
       "  149,\n",
       "  3,\n",
       "  32,\n",
       "  150,\n",
       "  6,\n",
       "  151,\n",
       "  19,\n",
       "  152,\n",
       "  153,\n",
       "  9,\n",
       "  154,\n",
       "  1,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  41,\n",
       "  7,\n",
       "  158,\n",
       "  2,\n",
       "  159,\n",
       "  21,\n",
       "  8,\n",
       "  37,\n",
       "  160,\n",
       "  4,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  6,\n",
       "  24,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  3,\n",
       "  167,\n",
       "  2,\n",
       "  168,\n",
       "  35,\n",
       "  20,\n",
       "  169,\n",
       "  3,\n",
       "  170,\n",
       "  1,\n",
       "  21,\n",
       "  171,\n",
       "  9,\n",
       "  40]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(stories)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\n",
    "#     [1, 2, 3, 4, 1, 5],\n",
    "#     [1, 6, 7, 8, 9],\n",
    "#     [10, 11, 12, 4, 1, 13]\n",
    "# ]\n",
    "## converts this code to this using\n",
    "# padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "# [\n",
    "#     [1, 2, 3, 4, 1, 5],    # Unchanged - already at max_len\n",
    "#     [1, 6, 7, 8, 9, 0],   # Padded with zeros at the end\n",
    "#     [10, 11, 12, 4, 1, 13]  # Unchanged - already at max_len\n",
    "# ]\n",
    "# # \n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator model\n",
    "generator = Sequential()\n",
    "generator.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "generator.add(Bidirectional(LSTM(128)))\n",
    "# activation='softmax' is used because the generator's output should represent \n",
    "# probabilities for each element in vocab_size in the vocabulary.\n",
    "generator.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "# Define discriminator model\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "discriminator.add(Bidirectional(LSTM(128)))\n",
    "discriminator.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# Combine models for GAN\n",
    "discriminator.trainable = False\n",
    "gan_input = generator.input\n",
    "gan_output = discriminator(gan_input)\n",
    "gan = Model(gan_input, gan_output)\n",
    "\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Epoch: 0, Generator Loss: 0.6927824020385742, Discriminator Loss: 0.6858948469161987\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Epoch: 10, Generator Loss: 0.6665546894073486, Discriminator Loss: 0.6346516609191895\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Epoch: 20, Generator Loss: 0.5360705256462097, Discriminator Loss: 0.3151545524597168\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Epoch: 30, Generator Loss: 0.06461039930582047, Discriminator Loss: 0.0345764085650444\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch: 40, Generator Loss: 0.017264321446418762, Discriminator Loss: 0.009681900963187218\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Epoch: 50, Generator Loss: 0.009558825753629208, Discriminator Loss: 0.005782551132142544\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Epoch: 60, Generator Loss: 0.006264679133892059, Discriminator Loss: 0.004005702678114176\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch: 70, Generator Loss: 0.004504249896854162, Discriminator Loss: 0.0029421320650726557\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch: 80, Generator Loss: 0.0034687956795096397, Discriminator Loss: 0.002288751071318984\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch: 90, Generator Loss: 0.0027777557261288166, Discriminator Loss: 0.0018840418197214603\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "for epoch in range(epochs):\n",
    "    # Generate noise data (fixed for better training stability)\n",
    "    noise = np.random.randint(0, vocab_size, size=(batch_size, max_len))\n",
    "\n",
    "    # Generate stories using the generator\n",
    "    generated_stories = generator.predict(noise)\n",
    "    max_real_len = real_stories.shape[1]\n",
    "    generated_stories = generated_stories[:, :max_real_len]\n",
    "\n",
    "    # Select real stories randomly\n",
    "    real_stories = padded_sequences[np.random.randint(0, len(padded_sequences), size=batch_size)]\n",
    "\n",
    "    # Concatenate real and generated stories\n",
    "    x_combined = np.concatenate([real_stories, generated_stories])\n",
    "\n",
    "    # Create labels\n",
    "    y_combined = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "\n",
    "    # Train discriminator\n",
    "    d_loss = discriminator.train_on_batch(x_combined, y_combined)\n",
    "\n",
    "    # Train generator to fool discriminator\n",
    "    y_mislabeled = np.ones((batch_size, 1))\n",
    "    g_loss = gan.train_on_batch(noise, y_mislabeled)\n",
    "\n",
    "    # Print and track loss\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Generator Loss: {g_loss}, Discriminator Loss: {d_loss}\")\n",
    "\n",
    "# Save the generator model for future use\n",
    "generator.save(\"text_generation_gan.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "Generated Story:\n",
      "i n   a   a   t i m e   a   a n d   a   t h e   t h e\n"
     ]
    }
   ],
   "source": [
    "# Generate a story\n",
    "def generate_story(seed_text, max_length=100):\n",
    "    generated = tokenizer.texts_to_sequences([seed_text])\n",
    "    for i in range(max_length):\n",
    "        padded = pad_sequences(generated, maxlen=max_len, padding='post')\n",
    "        prediction = np.argmax(generator.predict(padded), axis=-1)\n",
    "        generated[0].append(prediction[0])\n",
    "        if prediction == 0:\n",
    "            break\n",
    "    return ' '.join(tokenizer.sequences_to_texts(generated)[0])\n",
    "\n",
    "# Generate a story using the trained model\n",
    "seed_text = \"In a land far, far away, one upon a time there was a lion and a tiger.\"\n",
    "generated_story = generate_story(seed_text)\n",
    "print(\"Generated Story:\")\n",
    "print(generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 2, 2, 10, 2, 6, 2]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([seed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i n   a   a   t i m e   a   a n d   a   t h e   t h e'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x244334749d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00100108, 0.00100863, 0.0009958 , ..., 0.00100204, 0.00100405,\n",
       "        0.00099891],\n",
       "       [0.00099262, 0.00099682, 0.00099762, ..., 0.00100302, 0.00099641,\n",
       "        0.00100109],\n",
       "       [0.00099899, 0.00100128, 0.00100433, ..., 0.00099843, 0.00099495,\n",
       "        0.0010049 ],\n",
       "       ...,\n",
       "       [0.00099559, 0.00100589, 0.00100231, ..., 0.00099636, 0.00099853,\n",
       "        0.00100125],\n",
       "       [0.0009976 , 0.00099541, 0.00100342, ..., 0.00101211, 0.00099718,\n",
       "        0.00100451],\n",
       "       [0.00099189, 0.00099955, 0.0009974 , ..., 0.0009991 , 0.00099733,\n",
       "        0.00099985]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 67), (32, 67))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stories.shape, generated_stories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023494430352002382"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss = gan.train_on_batch(noise, y_mislabeled)\n",
    "\n",
    "g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.80000000e+01, 5.00000000e+00, 1.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.00000000e+00, 2.10000000e+01, 1.42000000e+02, ...,\n",
       "         1.71000000e+02, 9.00000000e+00, 4.00000000e+01],\n",
       "        [1.00000000e+00, 2.10000000e+01, 1.42000000e+02, ...,\n",
       "         1.71000000e+02, 9.00000000e+00, 4.00000000e+01],\n",
       "        ...,\n",
       "        [9.95585578e-04, 1.00589253e-03, 1.00230542e-03, ...,\n",
       "         9.96359158e-04, 9.98530886e-04, 1.00125244e-03],\n",
       "        [9.97600611e-04, 9.95408744e-04, 1.00342499e-03, ...,\n",
       "         1.01211248e-03, 9.97176045e-04, 1.00451428e-03],\n",
       "        [9.91886132e-04, 9.99549171e-04, 9.97404335e-04, ...,\n",
       "         9.99099924e-04, 9.97333671e-04, 9.99849639e-04]]),\n",
       " (64, 1))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_combined, y_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114,   4,  10, ...,   0,   0,   0],\n",
       "       [  1,  21, 142, ..., 171,   9,  40],\n",
       "       [ 18,   5,   1, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 18,   5,   1, ...,   0,   0,   0],\n",
       "       [  1,  90,  91, ...,   0,   0,   0],\n",
       "       [114,   4,  10, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hehe = np.random.randint(0, len(padded_sequences), size=batch_size)\n",
    "hehe\n",
    "padded_sequences[hehe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_stories_padded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# x_combined = np.concatenate([real_stories, generated_stories])\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m generated_stories\u001b[38;5;241m.\u001b[39mshape, \u001b[43mgenerated_stories_padded\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      3\u001b[0m generated_stories_padded, generated_stories\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generated_stories_padded' is not defined"
     ]
    }
   ],
   "source": [
    "# x_combined = np.concatenate([real_stories, generated_stories])\n",
    "generated_stories.shape, generated_stories_padded.shape\n",
    "generated_stories_padded, generated_stories\n",
    "    # y_combined = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
